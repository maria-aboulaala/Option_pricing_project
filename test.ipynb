{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=4 does not match number of samples=16",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\maria\\Documents\\GitHub\\Option_pricing_project\\test.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maria/Documents/GitHub/Option_pricing_project/test.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Create a decision tree regressor and fit it to the data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maria/Documents/GitHub/Option_pricing_project/test.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m tree_reg \u001b[39m=\u001b[39m DecisionTreeRegressor(max_depth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/maria/Documents/GitHub/Option_pricing_project/test.ipynb#W1sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m tree_reg\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maria/Documents/GitHub/Option_pricing_project/test.ipynb#W1sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Plot the decision tree\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/maria/Documents/GitHub/Option_pricing_project/test.ipynb#W1sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\maria\\Documents\\GitHub\\Option_pricing_project\\myenv\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\maria\\Documents\\GitHub\\Option_pricing_project\\myenv\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[0;32m   1321\u001b[0m         X,\n\u001b[0;32m   1322\u001b[0m         y,\n\u001b[0;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1325\u001b[0m     )\n\u001b[0;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maria\\Documents\\GitHub\\Option_pricing_project\\myenv\\lib\\site-packages\\sklearn\\tree\\_classes.py:366\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    363\u001b[0m max_leaf_nodes \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_leaf_nodes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_leaf_nodes\n\u001b[0;32m    365\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y) \u001b[39m!=\u001b[39m n_samples:\n\u001b[1;32m--> 366\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    367\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of labels=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m does not match number of samples=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(y), n_samples)\n\u001b[0;32m    369\u001b[0m     )\n\u001b[0;32m    371\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=4 does not match number of samples=16"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# Initialize parameters\n",
    "S0 = 100      # initial stock price\n",
    "K = 100       # strike price\n",
    "T = 1         # time to maturity in years\n",
    "r = 0.06      # annual risk-free rate\n",
    "N = 3         # number of time steps\n",
    "u = 1.1       # up-factor in binomial models\n",
    "d = 1/u       # ensure recombining tree\n",
    "\n",
    "# Precompute constants\n",
    "dt = T / N\n",
    "q = (np.exp(r * dt) - d) / (u - d)\n",
    "disc = np.exp(-r * dt)\n",
    "\n",
    "# Create binomial tree\n",
    "stock_tree = np.zeros((N+1, N+1))\n",
    "option_tree = np.zeros((N+1, N+1))\n",
    "\n",
    "for i in range(N+1):\n",
    "    for j in range(i+1):\n",
    "        stock_tree[j, i] = S0 * (u ** j) * (d ** (i - j))\n",
    "\n",
    "# Initialize option values at maturity\n",
    "option_tree[:, N] = np.maximum(stock_tree[:, N] - K, 0)\n",
    "\n",
    "# Step backwards through the tree to calculate option values\n",
    "for i in range(N-1, -1, -1):\n",
    "    for j in range(i+1):\n",
    "        option_tree[j, i] = disc * (q * option_tree[j, i+1] + (1 - q) * option_tree[j+1, i+1])\n",
    "\n",
    "# Flatten the stock_tree and option_tree arrays\n",
    "X = stock_tree.flatten().reshape(-1, 1)\n",
    "y = option_tree[:, 0]\n",
    "\n",
    "# Create a decision tree regressor and fit it to the data\n",
    "tree_reg = DecisionTreeRegressor(max_depth=3)\n",
    "tree_reg.fit(X, y)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_tree(tree_reg, filled=True, feature_names=['Stock Price'], class_names=['Option Value'])\n",
    "plt.title('Decision Tree for Binomial Option Pricing')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
